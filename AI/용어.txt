
AI와 LLM 범위
	AI:
	  머신러닝:
	    인공 신경망:
	      딥러닝:
		Gen AI(생성성 AI):
		  LLM

언어모델 범위
	Gen AI(생성형AI): 
	  LLM:
	    GPT:
	      GPT4:
		챗GPT

LLM : 
	LLM(Large Language Model, 대규모 언어 모델)은 방대한 텍스트 데이터를 학습하여 인간의 언어를 이해하고, 
	생성하며, 번역, 요약, 질의응답 등 다양한 자연어 처리(NLP) 작업을 수행하는 인공지능 모델입니다. 
	
	이는 트랜스포머 신경망 기반으로 작동하며, 
	'대규모'라는 이름처럼 엄청난 양의 데이터로 훈련되어 맥락을 파악하고 사람처럼 자연스러운 결과물을 만들어내는 것이 특징입니다. 
	
SLM :	SLM(Small Language Model), 
	특정 작업에 특화되어 처음부터 작게 설계된 모델입니다. 
	범용성보다는 명확한 목적을 가지고 설계되어 해당 영역에서는 오히려 대형 모델보다 뛰어난 성능을 보이기도 합니다.

sLLM : 
	sLLM(Smaller Large Language Model)은 기존의 거대 언어 모델(LLM)을 경량화하여, 
	더 적은 매개변수(파라미터)로도 특정 영역에서 높은 성능을 내도록 최적화한 모델로, 비용 효율성, 빠른 속도, 
	그리고 기업 내부망(온프레미스)에서의 보안성을 높여 맞춤형 AI 서비스에 적합합니다
	
트랜스포머 : 
	LLM 핵심 신경망 아키텍처, 트랜스포머를 이용한 대표적 언어 모델로는 BERT , GPT가 있다
	GPT의 'T'가 바로 트랜스포머를 의미합니다.
	
	버트(BERT): 
		'Bidirectional Encoder Representations from Transformers'의 약어로, 구글이 개발했습니다.
		텍스트를 양방향으로 분석하역 맥락을 이해하는 언어 모델.
		
	GPT:	
		GPT는 주로 Generative Pre-trained Transformer의 약자로, 
		방대한 텍스트 데이터를 미리 학습하여 인간처럼 자연스러운 글을 생성하고 이해하는 대규모 언어 모델(LLM)을 뜻하며, 
		OpenAI의 챗GPT가 대표적이며, 기술적으로는 변환기(Transformer) 아키텍처 기반의 신경망입니다. 


생성형 AI :
	생성형 AI(Generative AI)란 텍스트, 이미지, 음악, 코드 등 기존 데이터를 학습하여 스스로 새로운 콘텐츠를 창조해내는 인공지능 기술.
	사용자의 명령(프롬프트)에 따라 독창적이고 다양한 결과물을 만들어내며, 챗봇, 예술 창작, 소프트웨어 개발 등 다양한 분야에서 활용됩니다. 

AI 어시스턴트: 사용자의 명령에 따라 반응적으로 작업 수행 (예: "오늘 날씨 알려줘")

AI 에이전트: 목표(예: "주말 여행 계획 짜줘")를 주면, 스스로 검색, 비교, 예약까지 자율적으로 처리. 

RAG :
	RAG는 검색 증강 생성(Retrieval-Augmented Generation)의 약자로, 
	LLM(대규모 언어 모델)이 답변을 생성할 때 외부의 최신 정보나 기업 내부 데이터를 '검색(Retrieval)'하여 
	프롬프트를 '증강(Augmentation)'시킨 후, 
	이를 바탕으로 더 정확하고 신뢰성 높은 답변을 '생성(Generation)'하도록 돕는 기술입니다. 
	
	이는 모델의 학습 데이터 바깥의 최신 정보나 비공개 데이터를 활용하여 
	'환각(Hallucination)' 현상을 줄이고 답변의 정확성과 구체성을 높이는 데 핵심적인 역할을 합니다. 
	
랭체인 : 랭체인(LangChain)은 대규모 언어 모델(LLM) 기반 애플리케이션을 더 쉽고 효율적으로 개발할 수 있도록 돕는 오픈소스 프레임워크.	
		
랭그래프 : 랭그래프(LangGraph)는 복잡한 AI 워크플로우를 '그래프' 형태로 설계하고 관리할 수 있게 해주는 프레임워크.

랭스미스 : 랭스미스(LangSmith)는 대규모 언어 모델(LLM) 애플리케이션의 개발, 디버깅, 테스트 및 모니터링을 위한 플랫폼을 의미합니다. 

ReAct :
	추론 (Reasoning)->행동 (Acting)->관찰 (Observation)->다시 추론..
	'추론 및 행동(Reasoning and Acting)'의 약자. 
	대규모 언어 모델(LLM)이 복잡한 문제를 해결하기 위해 생각(추론)하고 외부 도구를 사용(행동)하는 방식을 결합한 프레임워크입니다
	
멀티모달 : 
	멀티모달(Multi-modal)은 텍스트, 이미지, 음성, 비디오 등 다양한 형태(모달리티)의 데이터를 동시에 이해하고 처리하여 
	인간처럼 자연스럽게 상호작용하는 기술로, 
	여러 감각 정보를 융합하여 더 깊이 있는 분석과 추론을 가능하게 하는 인공지능(AI)의 핵심 기술입니다. 
	
	기존 AI가 단일 데이터에 의존했다면, 멀티모달 AI는 이러한 데이터들을 통합하여 시너지 효과를 내고, 
	마치 사람이 여러 감각으로 세상을 이해하듯 사고하는 것이 특징입니다. 

-------
핵심 LLM 이용 기술
	
	트랜스포머 모델 (Transformer Model): 현재 대부분의 LLM이 사용하는 핵심 신경망 아키텍처입니다. 
	데이터 시퀀스의 여러 부분 간의 종속성을 파악하여 언어의 복잡성을 이해할 수 있게 해줍니다.
	
	토큰화 (Tokenization): 텍스트 데이터를 모델이 처리할 수 있는 '토큰'이라는 더 작은 단위로 분할하는 과정입니다.
	
	프롬프트 엔지니어링 (Prompt Engineering): 원하는 응답을 얻기 위해 모델에 입력하는 지시문(프롬프트)을 설계하고 최적화하는 기술입니다.
	
	미세 조정 (Fine-tuning): 특정 작업이나 도메인에 맞게 비교적 적은 양의 추가 데이터를 사용하여 이미 훈련된 LLM의 매개변수를 조정하는 기술입니다.
	
	검색 증강 생성 (RAG, Retrieval-Augmented Generation): 
		외부 데이터베이스나 문서에서 관련 정보를 검색하여 LLM의 응답 생성에 활용하는 기술입니다. 
		이를 통해 모델은 최신 정보를 기반으로 더 정확하고 신뢰할 수 있는 답변을 제공할 수 있으며, 
		기업 내부 데이터와 같은 민감한 정보의 보안을 유지하면서 활용할 수 있습니다.
	
	LLMOps (MLOps for LLMs): LLM 기반 애플리케이션의 개발, 배포, 테스트 및 모니터링 과정을 자동화하고 관리하는 운영 기술입니다.
	
	멀티모달 (Multimodal) LLM: 텍스트뿐만 아니라 이미지, 오디오와 같은 다양한 형태의 데이터를 이해하고 처리할 수 있는 기술입니다. 
	
---------

